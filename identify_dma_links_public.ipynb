{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5acc2ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import html as html\n",
    "import html2text\n",
    "import re\n",
    "import datetime as dt\n",
    "import random as rand\n",
    "from collections import defaultdict\n",
    "CONTRACTS_DIR = \"../contracts/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e78ac50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_START = 1 #days before fact_set announcement date to look for an SEC filing\n",
    "WINDOW_END = 45 #days after fact_set announcement date to look for an SEC filing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9cad104",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_set = pd.read_csv('fact_set_records.csv') #see paper for FactSet Columns\n",
    "fact_set_records = fact_set.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f30902b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = []\n",
    "with open('1000_common_words.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        common_words.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52a3593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct to the cusip to cik. Based on data from https://github.com/leoliu0/cik-cusip-mapping/blob/master/cik-cusip-maps.csv\n",
    "cusip_to_cik = pd.read_csv('cik-cusip-maps.csv')\n",
    "cusip_to_cik['cik'] = cusip_to_cik['cik'].astype(str)\n",
    "cusip_to_cik['cik'] = cusip_to_cik['cik'].apply(lambda x: x[0:x.find('.')])\n",
    "cusip_to_cik = cusip_to_cik.drop_duplicates(subset = ['cusip8'])\n",
    "cusip_to_cik = cusip_to_cik.set_index('cusip8')\n",
    "cusip_to_cik = cusip_to_cik.to_dict('index')\n",
    "for key, v in cusip_to_cik.items():\n",
    "    cusip_to_cik[key] = v['cik']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41962e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.read_csv(\"../contract_links_2000_2023_final.csv\")\n",
    "links['date.filed'] = links['date.filed'].apply(lambda x: pd.to_datetime(x))\n",
    "links = links.sort_values(by = ['date.filed', 'Unnamed: 0'])\n",
    "links['cik'] = links['cik'].apply(lambda x: str(x))\n",
    "ciks =  links['cik'].unique()\n",
    "links['exhibit_lead'] = links['exhibit'].apply(lambda x: x.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf87cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37000\n"
     ]
    }
   ],
   "source": [
    "for indx in range(0,len(fact_set_records)):\n",
    "    r = fact_set_records[indx]\n",
    "    try:\n",
    "        link, sc = dma_contract(r)\n",
    "        r['url'] = link\n",
    "        r['sc'] = sc\n",
    "    except:\n",
    "        print(\"error!\")\n",
    "        errors.append(r)\n",
    "    if indx % 1000 == 0:\n",
    "        print(indx)\n",
    "        pd.DataFrame(fact_set_records).to_csv('fact_set_records.csv')\n",
    "        pd.DataFrame(errors).to_csv('errors.csv')\n",
    "        with open('counter.txt', 'w') as f:\n",
    "            f.write('%d' % indx)\n",
    "        f.close()\n",
    "pd.DataFrame(fact_set_records).to_csv('fact_set_records.csv')\n",
    "pd.DataFrame(errors).to_csv('errors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee672700",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_cik_from_cusip(cusip):\n",
    "    cik = -1\n",
    "    try:\n",
    "        cik = cusip_to_cik[cusip[:8]]\n",
    "    except:\n",
    "        pass\n",
    "    if cik == -1:\n",
    "        try:\n",
    "            cik = cusip_to_cik[cusip[:6]]\n",
    "        except:\n",
    "            pass\n",
    "    return cik\n",
    "\n",
    "def clean_name(raw_name): #clean the names in the fact_set dataset\n",
    "    i_names = raw_name.split(';') #delimiter for names\n",
    "    names = []\n",
    "    for i_name in i_names:\n",
    "        name = i_name.lower()\n",
    "        names.append(name)\n",
    "        if '&' in name:\n",
    "            names.append(name.replace('&', 'and'))\n",
    "    final_names = []\n",
    "    suffix = ['inc', 'corp', 'corporation', 'incorpated', 'limited', 'llc', 'llp', 'lmt', 'ltd', 'co', 'lp', 'partners']\n",
    "    for name in names:\n",
    "        name = name.replace('.', '').replace(',','').replace('A/S', '').replace('  ',' ')\n",
    "        if name.count('(') > 0:\n",
    "            indx_1 = name.find('(')\n",
    "            indx_2 = name.find(')')\n",
    "            if indx_2 > indx_1: \n",
    "                name = name[:indx_1] + name[indx_2+1:]\n",
    "            else: #should never happen based on my data inspection\n",
    "                name.replace('(', '').replace(')','')\n",
    "        if name.count('/') > 0: #exclude the asset from company name\n",
    "            name = name[:name.find('/')]\n",
    "        if name == '-':\n",
    "            continue\n",
    "        final_names.append(name.strip())\n",
    "        t_name = name.lower().strip().split(' ')\n",
    "        t_name_end = t_name[-1]\n",
    "        for s in suffix: #add name without various corporate suffixes to make matching a bit easier\n",
    "            if t_name_end == s:\n",
    "                final_names.append(' '.join(t_name[:-1]))\n",
    "    return final_names\n",
    "def clean_cusips(cusips): #clean the cusips in fact_set dataset\n",
    "    cusips = cusips.split(';') #; delimited\n",
    "    final_cusips = []\n",
    "    for cusip in cusips:\n",
    "        cusip = cusip.strip()\n",
    "        if cusip == '-':\n",
    "            continue\n",
    "        final_cusips.append(cusip)\n",
    "    return final_cusips\n",
    "def get_company_info(data, target = 0):\n",
    "    if target == 0:\n",
    "        start = \"Acquirer\"\n",
    "    else: start = \"Target\"\n",
    "    company_info = {}\n",
    "    company_info['cusips'] = []\n",
    "    company_info['cusips'].extend(clean_cusips(data[start +' Cusip_fs']))\n",
    "    company_info['cusips'].extend(clean_cusips(data[start +' Ultimate Parent Cusip_fs']))\n",
    "    company_info['names'] = []\n",
    "    names = [data[start +'_fs'], data[start +' Ultimate Parent (At Deal)_fs']]\n",
    "    for name in names:\n",
    "        company_info['names'].extend(clean_name(name))\n",
    "    return company_info\n",
    "\n",
    "def find_ciks_from_cusip(company_info):\n",
    "    #print(company_info)\n",
    "    co_ciks = []\n",
    "    for cusip in company_info['cusips']:\n",
    "        cik = find_cik_from_cusip(cusip)\n",
    "        if cik in ciks:\n",
    "            co_ciks.append(cik)\n",
    "    return co_ciks\n",
    "\n",
    "\n",
    "def create_name_dict(t_links):\n",
    "    names_dict = t_links.drop_duplicates(subset = ['company.name'])\n",
    "    names_dict = names_dict.set_index('company.name')\n",
    "    names_dict = names_dict.to_dict('index')\n",
    "    names_dict_final = {}\n",
    "    for key, v in names_dict.items():\n",
    "        names_dict_final[key.lower()] = v['cik']\n",
    "    return names_dict_final\n",
    "\n",
    "def levenshteinDistance(s1, s2): #consider making a fast fail if this runs slow\n",
    "    if len(s1) > len(s2):\n",
    "        s1, s2 = s2, s1\n",
    "\n",
    "    distances = range(len(s1) + 1)\n",
    "    for i2, c2 in enumerate(s2):\n",
    "        distances_ = [i2+1]\n",
    "        for i1, c1 in enumerate(s1):\n",
    "            if c1 == c2:\n",
    "                distances_.append(distances[i1])\n",
    "            else:\n",
    "                distances_.append(1 + min((distances[i1], distances[i1 + 1], distances_[-1])))\n",
    "        distances = distances_\n",
    "    return distances[-1]\n",
    "\n",
    "def exclude_corp_suffix(name):\n",
    "    name.split(' ')\n",
    "\n",
    "\n",
    "def find_ciks_from_name(company_info, date):\n",
    "    ciks = []\n",
    "    window_start = date - dt.timedelta(days=WINDOW_START)\n",
    "    window_end = date + dt.timedelta(days=WINDOW_END)\n",
    "    t_links = links[links['date.filed'].apply(lambda x: x >= window_start and x<=window_end)] #only consider filings in window\n",
    "    name_to_cik = create_name_dict(t_links)\n",
    "    link_names = list(name_to_cik.keys())\n",
    "    for name in company_info['names']:\n",
    "        name = name.lower()\n",
    "        min_d = 1000\n",
    "        best_match = ''\n",
    "        for link_name in link_names:\n",
    "            d = levenshteinDistance(name, link_name)\n",
    "            if d < min_d:\n",
    "                best_match = link_name\n",
    "                min_d = d\n",
    "        #print (best_match)\n",
    "        if min_d < max(len(name)/3, 3) and min_d < 11: \n",
    "            #similarity threshold for a match - must be less than max(1/3 length, 3) and no more than 11\n",
    "            #arbitrarily tuned by hand for performance\n",
    "            #-----ideally will run tests on how threshold can be optimized for false positives / false negatives\n",
    "            ciks.append(name_to_cik[best_match])\n",
    "    return ciks\n",
    "\n",
    "def get_candidates(cik, date): #2000 has some odd filing formats - need a special case to deal with those\n",
    "    #print('cik: '+ cik)\n",
    "    t_links = links[links['cik'].apply(lambda x: str(x) == cik)]\n",
    "    #print(len(t_links))\n",
    "    window_start = date - dt.timedelta(days=WINDOW_START)\n",
    "    window_end = date + dt.timedelta(days=WINDOW_END)\n",
    "    t_links = t_links[t_links['date.filed'].apply(lambda x: x >= window_start and x<=window_end)]\n",
    "    #print(len(t_links))\n",
    "    cans= list(t_links['contract.link'])\n",
    "    #print (cans)\n",
    "    return cans\n",
    "\n",
    "\n",
    "def find_dma_contract(acq_company_info, dates, target_company_info):\n",
    "    acq_ciks = find_ciks_from_cusip(acq_company_info)\n",
    "    tar_ciks = find_ciks_from_cusip(target_company_info)\n",
    "    checked_links = []\n",
    "    acq_ciks_name = 'GO'\n",
    "    tar_ciks_name = 'GO'\n",
    "    acq_use_name = 1\n",
    "    tar_use_name = 1\n",
    "    \n",
    "    best_link = ''\n",
    "    best_score = 0\n",
    "    for date in dates: #test announcement date then completion date\n",
    "        #print(date)\n",
    "        for cik in acq_ciks: #test acquirer ciks\n",
    "            cans = get_candidates(cik, date)\n",
    "            for can in cans:\n",
    "                if can in checked_links: \n",
    "                    continue\n",
    "                checked_links.append(can)\n",
    "                sc = is_ma_agreement(can, target_company_info['names'], acq_company_info['names'])\n",
    "                if sc == 1: \n",
    "                    return can, 1\n",
    "                elif sc > best_score:\n",
    "                    best_link = can\n",
    "                    best_score = sc\n",
    "        for cik in tar_ciks: #test target ciks\n",
    "            cans = get_candidates(cik, date)\n",
    "            if cik in acq_ciks or cik in acq_ciks_name: #already tested cik\n",
    "                continue\n",
    "            for can in cans:\n",
    "                if can in checked_links: \n",
    "                    continue\n",
    "                checked_links.append(can)\n",
    "                sc = is_ma_agreement(can, acq_company_info['names'], target_company_info['names'])\n",
    "                if sc == 1: \n",
    "                    return can, 1\n",
    "                elif sc > best_score:\n",
    "                    best_link = can\n",
    "                    best_score = sc\n",
    "        if acq_ciks_name == 'GO':\n",
    "            acq_ciks_name = find_ciks_from_name(acq_company_info, date) #no hit from cusip - go to name\n",
    "        for cik in acq_ciks_name: #test acquier names\n",
    "            if cik in acq_ciks: #already tested cik\n",
    "                continue\n",
    "            cans = get_candidates(cik, date)\n",
    "            for can in cans:\n",
    "                if can in checked_links: \n",
    "                    continue\n",
    "                checked_links.append(can)\n",
    "                sc = is_ma_agreement(can, target_company_info['names'], acq_company_info['names'])\n",
    "                if sc == 1: \n",
    "                    return can, 1\n",
    "                elif sc > best_score:\n",
    "                    best_link = can\n",
    "                    best_score = sc\n",
    "        if tar_ciks_name == 'GO':\n",
    "            tar_ciks_name = find_ciks_from_name(target_company_info, date) #no hit from cusip - go to name\n",
    "        for cik in tar_ciks_name: #test target names\n",
    "            if cik in tar_ciks or cik in acq_ciks or cik in acq_ciks_name: #already tested cik\n",
    "                continue\n",
    "            cans = get_candidates(cik, date)\n",
    "            for can in cans:\n",
    "                if can in checked_links: \n",
    "                    continue\n",
    "                checked_links.append(can)\n",
    "                sc = is_ma_agreement(can, acq_company_info['names'], target_company_info['names'])\n",
    "                if sc == 1: return can, 1\n",
    "                elif sc > best_score:\n",
    "                    best_link = can\n",
    "                    best_score = sc\n",
    "    return best_link, best_score    \n",
    "def dma_contract(data):\n",
    "    acq_info = get_company_info(data)\n",
    "    target_info = get_company_info(data, target = 1)\n",
    "    dates_t = [data['Announcement Date_fs'], data['Completion Date_fs']] #sometimes need to check both dates\n",
    "    if dates_t[1] == dates_t[0]: dates_t = [dates_t[0]] #same date - no difference\n",
    "    dates = []\n",
    "    for date in dates_t:\n",
    "        try:\n",
    "            dates.append(pd.to_datetime(date))\n",
    "        except:\n",
    "            pass\n",
    "        if len(dates) > 1 and dates[1] - dates[0] < dt.timedelta(days=WINDOW_END):\n",
    "            dates[1] = dates[0] + dt.timedelta(days=WINDOW_END) + dt.timedelta(days=WINDOW_START) #ensure no overlap in dates\n",
    "    link, res = find_dma_contract(acq_info, dates, target_info) #acquier\n",
    "    if res == 0: #failed\n",
    "        return '', 0 #failure code\n",
    "    return \"https://www.sec.gov\"+link, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a1bbd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_match_score(text, names):\n",
    "    best = 0\n",
    "    for name in names:\n",
    "        name = name.lower()\n",
    "        split_name = name.split(' ')\n",
    "        if name in text: \n",
    "            if any(c.isalpha() for c in name) and len(name) > 4 and name not in common_words:\n",
    "                return 1 #exact match with sufficiently long name not in comon words\n",
    "            elif name not in common_words: #exact match with a shorter name\n",
    "                if best < .8: best = .8\n",
    "            else: #exact match with a shorter, common name - not enough to report a real match\n",
    "                best = .49\n",
    "        if len(split_name) > 2:\n",
    "            if ' '.join(split_name[:-1]) in text: #just last word missing\n",
    "                best = .99\n",
    "        if len(split_name) > 3: #just two words missing\n",
    "            if ' '.join(split_name[:-2]) in text: \n",
    "                if best < .95: best = .95\n",
    "        t = [split_name[0]+' ', split_name[0]+',', split_name[0]+'.', split_name[0]+'\\n'] #check for first word match\n",
    "        if any(t_name in text for t_name in t):\n",
    "            if split_name[0] in common_words:\n",
    "                continue\n",
    "            if any(c.isalpha() for c in split_name[0]):\n",
    "                if len(split_name[0]) > 3:\n",
    "                    if best < .9: best = .9\n",
    "                if best < .8: best = .8\n",
    "            else:\n",
    "                if len(split_name[0]) > 4:\n",
    "                    if best < .8: best = .8\n",
    "                else:\n",
    "                    if best < .51: best = .51\n",
    "    return best\n",
    "\n",
    "\n",
    "def is_ma_agreement(contract_link, non_filer_names = [], filer_names= []): #run cell below first for relevant code\n",
    "    text = extract_text(get_filename(contract_link)).lower()\n",
    "    text = text.replace('\\n\\n', ' ')\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    types = contract_type(text, types_dict)\n",
    "    reported_type = types['type']\n",
    "    name_match_filer = name_match_score(text[:1000], filer_names)\n",
    "    name_match_non_filer = name_match_score (text[:1000], non_filer_names)\n",
    "    if reported_type == 'ma':\n",
    "        return max(name_match_non_filer, .51)\n",
    "    elif reported_type == 'asset':\n",
    "        return max(name_match_non_filer, .5)\n",
    "    elif reported_type == 'equity':\n",
    "        return max(name_match_non_filer, .4)\n",
    "    else: #catch for catch-all phrases\n",
    "        catch_alls = ['sale and purchase agreement', 'purchase and sale agreement', \n",
    "                      'purchase agreement', 'agreement of purchase and sale',\n",
    "                     'agreement of sale and purchase', 'contribution agreement', \n",
    "                      'contribution, convetance, assumption, and simplification agreement',\n",
    "                     \"sale agreement\", 'transaction agreement']\n",
    "        start = text[:1000].replace('\\n',' ').replace('   ', ' ').replace('  ',' ')\n",
    "        if any(agreement in start for agreement in catch_alls):\n",
    "            if name_match_non_filer > .5:\n",
    "                return (name_match_non_filer + name_match_filer) / 2\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5da8cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def get_filename(contract_link):\n",
    "    ls = contract_link.split(\"/\")\n",
    "    fn = ls[4]+\"..\"+ls[5]+\"..\"+ls[6]\n",
    "    return fn\n",
    "def extract_text(fn): #given a file name for a scraped contract, open the file, extract the text, and perform some cleaning functions\n",
    "    try:\n",
    "        with open(CONTRACTS_DIR+fn, \"rb\") as f:\n",
    "            htm = f.read().decode('utf8')\n",
    "            htm = re.sub('&#147;', '\\\"', htm)\n",
    "            htm = re.sub('&#148;', '\\\"', htm)\n",
    "            htm = re.sub('<B>', '', htm)\n",
    "            htm = re.sub('</B>', '', htm)\n",
    "            if len(htm) > 9000000:\n",
    "                print('LARGE_FILE')\n",
    "                raise Exception('file big - defer')\n",
    "            text = html2text.html2text(htm)\n",
    "            document_text = text.replace('\\\\t', '')\n",
    "            document_text = re.sub('\\n.{0,10}\\n.{0,10}\\n.{0,10}\\n.{0,10}\\n*\\* \\* \\*\\n+(.*)\\n+', ' ', document_text) \n",
    "            document_text = re.sub(r'\\n +\\n', '\\n\\n', document_text)\n",
    "            document_text = re.sub(r'  +', ' ', document_text)\n",
    "            document_text = document_text.replace('&amp;', 'and')\n",
    "            document_text = document_text.replace('&', 'and')\n",
    "            document_text = document_text.replace(\"\\\\n\", \" \") #files have a lot of extra \\\\n \n",
    "            #document_text = document_text.replace('\\n\\n', 'SPLITTEXTHERE') #consider applying when you use text, but not when extracting raw\n",
    "            #document_text = re.sub(r'\\s+', ' ', document_text) #consider applying when you use text, but not when extracting raw text\n",
    "            #document_text = document_text.encode('utf-8').decode('utf-8')\n",
    "        return document_text\n",
    "    except:\n",
    "        print(\"ERROR\")\n",
    "        raise Exception('error reading file')\n",
    "def contract_type(text, types_dict): #HOW TO DEAL WITH AMENDED AND RESTATED AGREEMENTS - RESTATED MEANS IT's A FULL CONTRACT\n",
    "    ''' A Function that accepts a string (here, the first instance of agreement and the preceding words) and a dictionary\n",
    "    with words that defines triggers to categorize the type of contract. Keys needs to be ma, license, legal, loan, employment and\n",
    "    incentive'''\n",
    "    # In my understanding, you look for the first occurence of a \"format\" word, and then pulls all text ahead of it.\n",
    "    # This function then categorizes the contract based on the first occurrence of a keyword\n",
    "    #This function also categorizes contracts as ammendments based on the text before the format word\n",
    "\n",
    "    my_dict = {}\n",
    "    the_keys = types_dict.keys()\n",
    "    the_type = 'undefined'\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\n\", ' ', text)\n",
    "    text = re.sub(\"\\t\", ' ', text)\n",
    "    text = re.sub(r\"[/-]\", ' ', text)\n",
    "    text = re.sub(r\"[^a-z ]+\", '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    formats = [\"agreement\", \"plan\", \"note\", \"policy\", \"guideline\", \"program\", \"contract\"]\n",
    "    \n",
    "    occurrences = {}\n",
    "    for word in formats:\n",
    "        position = text.find(' '+word)\n",
    "        if position == -1:\n",
    "            continue\n",
    "        occurrences[word] = position\n",
    "    if len(occurrences) > 0:\n",
    "        the_format = min(occurrences, key=occurrences.get)\n",
    "    else: the_format = 'undefined'\n",
    "    \n",
    "    occurrences = {}\n",
    "    for key in the_keys:\n",
    "        word_list = types_dict[key]\n",
    "        for word in word_list:\n",
    "            position = text.find(' '+word)\n",
    "            if position == -1:\n",
    "                continue\n",
    "            occurrences[word] = position\n",
    "    if len(occurrences) > 0:\n",
    "        the_word = min(occurrences, key=occurrences.get)\n",
    "        pos = occurrences[the_word]\n",
    "        relevant_text = text[: min(len(text), pos+50)]\n",
    "    else:\n",
    "        the_word = 'undefined'\n",
    "        relevant_text = \"\"\n",
    "    \n",
    "    for k, v in types_dict.items():\n",
    "        if the_word in v:\n",
    "            the_type = k\n",
    "    \n",
    "    #print the_type\n",
    "    my_dict['type'] = the_type\n",
    "    if 'amendm' in relevant_text or 'amending' in relevant_text:\n",
    "        my_dict['amendment'] = 1\n",
    "    else:\n",
    "        my_dict['amendment'] = 0\n",
    "    if 'restat' in relevant_text:\n",
    "        my_dict['restate'] = 1\n",
    "    else:\n",
    "        my_dict['restate'] = 0\n",
    "    my_dict['type_hit_word'] = the_word\n",
    "    my_dict['type_text'] = relevant_text\n",
    "    my_dict['format'] = the_format\n",
    "\n",
    "    \n",
    "\n",
    "    return my_dict\n",
    "# Agreement Types and their respective word triggers - taken from Julian Nyarko's old code\n",
    "\n",
    "incentives = (\"pension\", 'stock unit', 'award', 'incentive', 'compensation',\n",
    "    'management stability', 'stock option', 'restricted stock', \n",
    "    'tax deferred savings',\n",
    "    'reimbursement', 'retention', \n",
    "    'separation allowance', 'retirement', 'bonus', 'dsu', 'medical plan', 'benefit', 'indemnification', 'health plan',\n",
    "    'executive plan', 'savings and investment', 'stock ownership', 'restoration plan', 'performance share', 'stock retainer',\n",
    "             'performance plan', 'management stockholders', 'indemnity', 'director stock', 'directors stock')\n",
    "\n",
    "other = ('registration rights', 'omnibus', 'general conditions', 'share appreciation', 'limited liability company agreement')\n",
    "\n",
    "employment = ('employer', 'employee', 'employment','severance', 'non competition', 'termination', 'management continuity', \n",
    "              'transition', 'appointment') \n",
    "\n",
    "lease = ('lease', 'line access', 'sublease', 'tenant', 'landlord')\n",
    "\n",
    "sales = ('distribution', 'repurchase')\n",
    "\n",
    "ni = ('promissory', 'absldas')\n",
    "\n",
    "equity_purchase = ('share purchase', 'stock purchase', 'securities purchase','share exchange', 'unit purchase agreement',\n",
    "                   'membership interest purchase', 'membership interest exchange', \n",
    "                    'membership interests purchase', 'membership interests exchange', \n",
    "                    \"membership interest contribution\", \"membership interests contribution\",\n",
    "                   'equity purchase', 'equity exchange', 'stock exchange agreement',\n",
    "                  \"share sale\", \"share swap\", \"equity interests purchase\", \"interest purchase agreement\")\n",
    "asset_purchase = ('asset purchase', 'asset purchase agreement', 'asset sale')\n",
    "\n",
    "loan = ('credit', 'loan', 'subordination',\n",
    "       'borrow', 'lender', 'commitment')\n",
    " \n",
    "ma = ( 'merger',  'arrangement agreement','acquisition agreement', 'amalgamation', 'combination')\n",
    "#ma = ('change in control', 'change of control', 'share exchange', 'merger', 'separation and distribution', 'earnout', 'earn out')\n",
    "#add cooperation? - going to miss e.g. take-two takeover agreement (first contract in csv)\n",
    "\n",
    "jv = ('joint venture', 'point penture')\n",
    "    \n",
    "license = ('license', 'licensing')\n",
    "\n",
    "legal = ('settlement', 'tolling', 'waiver')\n",
    "\n",
    "\n",
    "types_dict = {}\n",
    "types_dict['incentives'] = incentives\n",
    "types_dict['employment'] = employment\n",
    "types_dict['asset'] = asset_purchase\n",
    "types_dict['equity'] = equity_purchase\n",
    "types_dict['sales'] = sales\n",
    "types_dict['loan'] = loan\n",
    "types_dict['ma'] = ma\n",
    "types_dict['license'] = license\n",
    "types_dict['legal'] = legal\n",
    "types_dict['lease'] = lease\n",
    "types_dict['ni'] = ni\n",
    "types_dict['jv'] = jv\n",
    "types_dict['other'] = other"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
